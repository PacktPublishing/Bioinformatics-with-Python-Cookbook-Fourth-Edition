{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a512488-4364-48dc-9d72-8dfd1e8749d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ch16-2 Protein Design with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea4c46-9a55-41fa-8086-af767845e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages \n",
    "! pip install torch transformers numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f18781a-6883-4916-9f5c-867bf4187629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80db7b-be9f-4e69-9ec2-ff1f6f71252e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7909e2-78c4-4aa4-b68b-d7b7635f93c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtGPT2 Protein Design Example\n",
      "===============================\n",
      "This example demonstrates how to use ProtGPT2 for protein design.\n",
      "Make sure you have installed: torch, transformers, numpy\n",
      "\n",
      "Loading ProtGPT2 model and tokenizer...\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "============================================================\n",
      "EXAMPLE 1: De novo protein generation\n",
      "============================================================\n",
      "Generating 3 protein sequence(s)...\n",
      "\n",
      "Generated Protein 1:\n",
      "Sequence: MNRIACIDIGLKTIGFAVSDKTNTLAFPVKVLKRKNIKKELIKLKKIIEEEKPEIVIVGL\n",
      "PLNMDGTLGPMAKKTQKFAYLLKEKIKLPIYTIDERLSSFEADKILIESGASKKKRKKIV\n",
      "DKIAAVYILQGYLDAI\n",
      "Length: 136 amino acids\n",
      "Validity: 1.000\n",
      "Valid: True\n",
      "\n",
      "Generated Protein 2:\n",
      "Sequence: MDTPDWQQAWQTHFQNQPAIPHQPHHQGQNQPFPHQPHHQGQNQPFPHQPHHQGQNQPFP\n",
      "HQPHHQGQNQPFPHQPHHQGQNQPFPHQPHHQGQNQPFPHQPHHQGQNQPFPHQPHHQGQ\n",
      "NQPFPHQPHHQGQNQPFPHQPHHQGQNQPFPHQPHHQGQNQPFPHQPHHQGQNQPFPHQP\n",
      "HHQGQNQPFPHQPHHQGQNQPFPHQP\n",
      "Length: 206 amino acids\n",
      "Validity: 1.000\n",
      "Valid: True\n",
      "\n",
      "Generated Protein 3:\n",
      "Sequence: MIYDYFIFCSRNYSNDRTNYIIFHKNEFIRYNTSEYINNIIYYHNIFRYNYYNKYIFRYN\n",
      "KYIFRYNNYYKYIFRYNNYILRYNNYILRYNNYILRYNNYILRYNNYILRYNNYILRYNN\n",
      "YILRYNNYILRYNNYILRYNNYILRYNNYILRYNNYILRYNNYILRYNNYILRYNNYILR\n",
      "YNNYILRYNNYILRYNNYILRYNNYILRYNNYIL\n",
      "Length: 214 amino acids\n",
      "Validity: 1.000\n",
      "Valid: True\n",
      "\n",
      "============================================================\n",
      "EXAMPLE 2: Protein generation with a starting motif\n",
      "============================================================\n",
      "Generating 2 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Motif-based Protein 1:\n",
      "Sequence: MKKLLFLLLILGLSISCSDDDNNGGGNSNPPPDYNALIIGKWESVYQYTGTNENGNVVTN\n",
      "EYTCDDDNTFVFNDDGTVEIYNDGTEDCNETTSTGTWSLSADGLTLTTEEGTETYTLTTL\n",
      "NSTTLTITESATVDGVTETETEEYTF\n",
      "Length: 146 amino acids\n",
      "Validity: 1.000\n",
      "\n",
      "Motif-based Protein 2:\n",
      "Sequence: MKKLLFASLFLFAGLLFAQENTLKVEKDFFELKSSFNYESYDENTKRNTAKLNYYNFNLN\n",
      "GYYYPNEKWSVGLGMGYNKDKINTNIDGVTYKSSGDGFAITPFIKYYFNQENKLAPFVSF\n",
      "GYNYQTFKYKNEDLKTSTSAFGVGVKVGVNYFINDQLGLDVNVGYLGYKKLESENDNKNT\n",
      "NNISFGFNIGYRF\n",
      "Length: 193 amino acids\n",
      "Validity: 1.000\n",
      "\n",
      "============================================================\n",
      "EXAMPLE 3: Constrained protein design\n",
      "============================================================\n",
      "Designing proteins with target length ~120 amino acids...\n",
      "Generating 1 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid design found (attempt 10): Length=125, Validity=1.000\n",
      "Generating 1 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 protein sequence(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 protein sequence(s)...\n",
      "\n",
      "Found 1 valid designs:\n",
      "\n",
      "Design 1:\n",
      "Sequence: MTALLALLALLVLVPLAVRRLPRGPVGTLLAGALALAVAAAVAGGLLAAPDGRAGARLLGLALLLAGLAALVARRARPAPAAPRGVAALLAAAGALLLLGLLAPGLLPAPPGLAPPPGAAAGAGP\n",
      "Length: 125 amino acids\n",
      "Validity: 1.000\n",
      "Hydrophobic content: 0.768\n",
      "Charged content: 0.080\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ProtGPT2 Protein Design Example\n",
    "This script demonstrates how to use ProtGPT2 to generate novel protein sequences.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ProtGPT2Designer:\n",
    "    \"\"\"A wrapper class for protein design using ProtGPT2.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"nferruz/ProtGPT2\"):\n",
    "        \"\"\"\n",
    "        Initialize the ProtGPT2 model and tokenizer.\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model identifier for ProtGPT2\n",
    "        \"\"\"\n",
    "        print(\"Loading ProtGPT2 model and tokenizer...\")\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Load model and tokenizer\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Set pad token\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        print(\"Model loaded successfully!\")\n",
    "    \n",
    "    def generate_protein(self, \n",
    "                        prompt: str = \"<|endoftext|>\",\n",
    "                        max_length: int = 200,\n",
    "                        temperature: float = 1.0,\n",
    "                        num_sequences: int = 1,\n",
    "                        do_sample: bool = True,\n",
    "                        top_p: float = 0.9) -> List[str]:\n",
    "        \"\"\"\n",
    "        Generate protein sequences using ProtGPT2.\n",
    "        \n",
    "        Args:\n",
    "            prompt: Starting sequence or prompt (use \"<|endoftext|>\" for de novo generation)\n",
    "            max_length: Maximum length of generated sequence\n",
    "            temperature: Sampling temperature (higher = more random)\n",
    "            num_sequences: Number of sequences to generate\n",
    "            do_sample: Whether to use sampling (vs greedy decoding)\n",
    "            top_p: Top-p sampling parameter\n",
    "            \n",
    "        Returns:\n",
    "            List of generated protein sequences\n",
    "        \"\"\"\n",
    "        print(f\"Generating {num_sequences} protein sequence(s)...\")\n",
    "        \n",
    "        # Encode the prompt\n",
    "        inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        \n",
    "        # Generate sequences\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                inputs,\n",
    "                max_length=max_length,\n",
    "                temperature=temperature,\n",
    "                num_return_sequences=num_sequences,\n",
    "                do_sample=do_sample,\n",
    "                top_p=top_p,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                eos_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        # Decode sequences\n",
    "        sequences = []\n",
    "        for output in outputs:\n",
    "            sequence = self.tokenizer.decode(output, skip_special_tokens=True)\n",
    "            # Clean up the sequence (remove prompt if present)\n",
    "            if prompt != \"<|endoftext|>\" and sequence.startswith(prompt):\n",
    "                sequence = sequence[len(prompt):]\n",
    "            sequences.append(sequence.strip())\n",
    "        \n",
    "        return sequences\n",
    "    \n",
    "    def validate_sequence(self, sequence: str) -> dict:\n",
    "        \"\"\"\n",
    "        Basic validation of a protein sequence.\n",
    "        \n",
    "        Args:\n",
    "            sequence: Protein sequence to validate\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with validation results\n",
    "        \"\"\"\n",
    "        # Standard amino acids\n",
    "        standard_aa = set('ACDEFGHIKLMNPQRSTVWY')\n",
    "        \n",
    "        # Clean sequence (remove whitespace and convert to uppercase)\n",
    "        clean_seq = re.sub(r'\\s+', '', sequence.upper())\n",
    "        \n",
    "        # Calculate statistics\n",
    "        length = len(clean_seq)\n",
    "        valid_aa = sum(1 for aa in clean_seq if aa in standard_aa)\n",
    "        invalid_aa = length - valid_aa\n",
    "        validity_ratio = valid_aa / length if length > 0 else 0\n",
    "        \n",
    "        # Calculate amino acid composition\n",
    "        aa_counts = {aa: clean_seq.count(aa) for aa in standard_aa}\n",
    "        aa_frequencies = {aa: count/length for aa, count in aa_counts.items() if length > 0}\n",
    "        \n",
    "        return {\n",
    "            'sequence': clean_seq,\n",
    "            'length': length,\n",
    "            'valid_amino_acids': valid_aa,\n",
    "            'invalid_amino_acids': invalid_aa,\n",
    "            'validity_ratio': validity_ratio,\n",
    "            'is_valid': validity_ratio > 0.95,  # At least 95% valid amino acids\n",
    "            'amino_acid_composition': aa_frequencies\n",
    "        }\n",
    "    \n",
    "    def design_proteins_with_constraints(self, \n",
    "                                       target_length: int = 150,\n",
    "                                       num_attempts: int = 10,\n",
    "                                       min_validity: float = 0.95) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Design proteins with specific constraints.\n",
    "        \n",
    "        Args:\n",
    "            target_length: Desired protein length\n",
    "            num_attempts: Number of generation attempts\n",
    "            min_validity: Minimum validity ratio required\n",
    "            \n",
    "        Returns:\n",
    "            List of validated protein designs\n",
    "        \"\"\"\n",
    "        print(f\"Designing proteins with target length ~{target_length} amino acids...\")\n",
    "        \n",
    "        valid_designs = []\n",
    "        \n",
    "        for attempt in range(num_attempts):\n",
    "            # Generate sequence\n",
    "            sequences = self.generate_protein(\n",
    "                max_length=target_length + 50,  # Allow some flexibility\n",
    "                temperature=0.8,\n",
    "                num_sequences=1\n",
    "            )\n",
    "            \n",
    "            for seq in sequences:\n",
    "                validation = self.validate_sequence(seq)\n",
    "                \n",
    "                # Check constraints\n",
    "                if (validation['validity_ratio'] >= min_validity and \n",
    "                    abs(validation['length'] - target_length) <= target_length * 0.2):  # Within 20% of target\n",
    "                    \n",
    "                    validation['attempt'] = attempt + 1\n",
    "                    valid_designs.append(validation)\n",
    "                    print(f\"Valid design found (attempt {attempt + 1}): \"\n",
    "                          f\"Length={validation['length']}, \"\n",
    "                          f\"Validity={validation['validity_ratio']:.3f}\")\n",
    "        \n",
    "        return valid_designs\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function demonstrating ProtGPT2 usage.\"\"\"\n",
    "    \n",
    "    # Initialize the designer\n",
    "    designer = ProtGPT2Designer()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXAMPLE 1: De novo protein generation\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Generate de novo proteins\n",
    "    sequences = designer.generate_protein(\n",
    "        prompt=\"<|endoftext|>\",\n",
    "        max_length=100,\n",
    "        temperature=0.8,\n",
    "        num_sequences=3\n",
    "    )\n",
    "    \n",
    "    for i, seq in enumerate(sequences, 1):\n",
    "        print(f\"\\nGenerated Protein {i}:\")\n",
    "        print(f\"Sequence: {seq}\")\n",
    "        \n",
    "        # Validate the sequence\n",
    "        validation = designer.validate_sequence(seq)\n",
    "        print(f\"Length: {validation['length']} amino acids\")\n",
    "        print(f\"Validity: {validation['validity_ratio']:.3f}\")\n",
    "        print(f\"Valid: {validation['is_valid']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXAMPLE 2: Protein generation with a starting motif\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Generate proteins starting with a specific motif\n",
    "    motif_sequences = designer.generate_protein(\n",
    "        prompt=\"MKKLLF\",  # Starting with a signal peptide-like motif\n",
    "        max_length=150,\n",
    "        temperature=0.7,\n",
    "        num_sequences=2\n",
    "    )\n",
    "    \n",
    "    for i, seq in enumerate(motif_sequences, 1):\n",
    "        print(f\"\\nMotif-based Protein {i}:\")\n",
    "        print(f\"Sequence: MKKLLF{seq}\")\n",
    "        validation = designer.validate_sequence(f\"MKKLLF{seq}\")\n",
    "        print(f\"Length: {validation['length']} amino acids\")\n",
    "        print(f\"Validity: {validation['validity_ratio']:.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXAMPLE 3: Constrained protein design\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Design proteins with specific constraints\n",
    "    constrained_designs = designer.design_proteins_with_constraints(\n",
    "        target_length=120,\n",
    "        num_attempts=15,\n",
    "        min_validity=0.98\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nFound {len(constrained_designs)} valid designs:\")\n",
    "    for i, design in enumerate(constrained_designs[:3], 1):  # Show first 3\n",
    "        print(f\"\\nDesign {i}:\")\n",
    "        print(f\"Sequence: {design['sequence']}\")\n",
    "        print(f\"Length: {design['length']} amino acids\")\n",
    "        print(f\"Validity: {design['validity_ratio']:.3f}\")\n",
    "        \n",
    "        # Show amino acid composition for interesting residues\n",
    "        composition = design['amino_acid_composition']\n",
    "        hydrophobic = sum(composition.get(aa, 0) for aa in 'AILMFPWV')\n",
    "        charged = sum(composition.get(aa, 0) for aa in 'DEKR')\n",
    "        print(f\"Hydrophobic content: {hydrophobic:.3f}\")\n",
    "        print(f\"Charged content: {charged:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Install required packages first:\n",
    "    # pip install torch transformers numpy\n",
    "    \n",
    "    print(\"ProtGPT2 Protein Design Example\")\n",
    "    print(\"===============================\")\n",
    "    print(\"This example demonstrates how to use ProtGPT2 for protein design.\")\n",
    "    print(\"Make sure you have installed: torch, transformers, numpy\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        main()\n",
    "    except ImportError as e:\n",
    "        print(f\"Missing required package: {e}\")\n",
    "        print(\"Please install required packages:\")\n",
    "        print(\"pip install torch transformers numpy\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Make sure you have an internet connection to download the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacb9c75-3ec9-49e0-ba7f-e4e0e4820ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ec62f-ebc1-4987-804b-8a35618973a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0e9a7-4e17-477c-b601-fbf64508f79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295349f-4e33-443a-ac16-658aa2afe91b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
